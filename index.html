<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BMSFormerï¼šé¢å‘èµ„æºå—é™BMSçš„é«˜æ•ˆé”‚ç”µæ± SOHåœ¨çº¿ä¼°ç®—æ¨¡å‹</title>
    <style>
        :root {
            --primary-color: #2c3e50;
            --accent-color: #3498db;     /* è“è‰² */
            --note-tag-color: #c0392b;   /* ã€å­¦ä¹ ç¬”è®°ã€‘çš„æ·±çº¢è‰² */
            --divider-color: #d35400;    /* æ©™è‰²è£…é¥°çº¿ */
            --bg-color: #ffffff;
            --text-color: #333;
            --sidebar-width: 280px;
            --content-max-width: 1250px;
            --hover-border-color: #1e5f99;
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: "Helvetica Neue", Helvetica, Arial, "PingFang SC", "Microsoft YaHei", sans-serif;
            background-color: var(--bg-color);
            color: var(--text-color);
            line-height: 1.8;
            display: flex;
            min-height: 100vh;
        }

        /* --- å¤šè¯­è¨€åˆ‡æ¢å™¨æ ·å¼ (æ–°å¢) --- */
        .lang-switch-wrapper {
            position: fixed;
            top: 20px;
            right: 30px;
            z-index: 10000;
        }

        .lang-select {
            padding: 8px 12px;
            font-size: 0.9rem;
            border: 1px solid #ddd;
            border-radius: 4px;
            background-color: white;
            color: #333;
            cursor: pointer;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            outline: none;
            transition: all 0.3s;
            font-family: inherit;
            font-weight: 500;
        }

        .lang-select:hover {
            border-color: var(--accent-color);
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        }

        /* --- å·¦ä¾§å¯¼èˆªæ æ ·å¼ --- */
        nav.sidebar {
            width: var(--sidebar-width);
            background-color: #f9f9f9;
            height: 100vh;
            position: fixed;
            left: 0;
            top: 0;
            overflow-y: auto;
            border-right: 1px solid #ddd;
            padding: 20px;
            z-index: 100;
        }

        nav.sidebar h3 {
            font-size: 1.1rem;
            margin-bottom: 20px;
            color: var(--primary-color);
            border-bottom: 2px solid var(--accent-color);
            padding-bottom: 10px;
        }

        nav.sidebar ul { list-style: none; }
        nav.sidebar li { margin-bottom: 8px; }
        nav.sidebar a {
            text-decoration: none;
            color: #555;
            display: block;
            padding: 6px 10px;
            border-radius: 4px;
            transition: all 0.2s;
            font-size: 0.9rem;
        }
        nav.sidebar a:hover {
            background-color: #eaf6ff;
            color: var(--accent-color);
        }
        nav.sidebar .sub-menu {
            margin-left: 15px;
            font-size: 0.85rem;
            border-left: 2px solid #eee;
        }

        /* --- å³ä¾§ä¸»è¦å†…å®¹æ ·å¼ --- */
        main.content {
            margin-left: var(--sidebar-width);
            flex: 1;
            padding: 50px;
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        .content-block {
            width: 100%;
            max-width: var(--content-max-width);
        }

        .content-block p {
            font-size: 1.15rem;
            text-align: justify;
            margin-bottom: 1.5em;
            line-height: 1.9;
            color: #444;
        }

        /* --- å¤´éƒ¨è®¾è®¡ --- */
        header.article-header {
            text-align: center;
            margin-bottom: 40px;
            width: 100%;
        }

        h1.main-title {
            font-size: 2.2rem;
            margin-bottom: 15px;
            font-weight: 700;
            color: #000;
            white-space: normal; /* å…è®¸æ¢è¡Œä»¥é€‚åº”é•¿æ ‡é¢˜ */
        }

        .note-tag {
            color: var(--note-tag-color);
            margin-right: 10px;
        }

        .title-divider {
            width: 200px;
            height: 5px;
            background-color: var(--divider-color);
            margin: 0 auto 30px auto;
            border-radius: 2px;
        }

        .header-buttons {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-bottom: 40px;
        }

        .header-btn {
            display: inline-flex;
            align-items: center;
            padding: 8px 20px;
            background-color: #fff;
            border: 1px solid #ddd;
            border-radius: 4px;
            text-decoration: none;
            color: #555;
            font-size: 0.95rem;
            transition: all 0.3s;
            box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        }

        .header-btn:hover {
            background-color: #f8f9fa;
            border-color: #bbb;
            color: #000;
        }

        .header-btn svg {
            margin-right: 8px;
            width: 16px;
            height: 16px;
            fill: #666;
        }

        .paper-info-box {
            background-color: #f8f9fa;
            border-left: 6px solid #1e5f99;
            padding: 25px 30px;
            text-align: left;
            border-radius: 0 4px 4px 0;
            margin-bottom: 40px;
            color: #444;
            font-size: 1rem;
            line-height: 1.8;
            width: 100%;
        }

        .paper-info-box strong {
            color: #2c3e50;
            font-weight: 600;
        }

        /* --- ç« èŠ‚æ ·å¼ --- */
        section {
            background: white;
            margin-bottom: 40px;
            width: 100%;
            scroll-margin-top: 20px;
        }

        h2 {
            color: var(--primary-color);
            border-bottom: 1px solid #eee;
            padding-bottom: 15px;
            margin-bottom: 25px;
            font-size: 1.6rem;
        }

        h3 {
            color: #333;
            margin-top: 30px;
            margin-bottom: 15px;
            font-size: 1.3rem;
            display: flex;
            align-items: center;
            font-weight: 600;
        }

        h3::before {
            content: '';
            display: inline-block;
            width: 5px;
            height: 22px;
            background-color: var(--accent-color);
            margin-right: 12px;
            border-radius: 2px;
        }

        /* --- å›¾ç‰‡å®¹å™¨ä¸è¯´æ˜æ–‡å­— --- */
        .img-wrapper {
            width: 100%;
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 35px 0;
        }

        .content-img {
            width: auto;
            max-width: 90%;
            max-height: 800px;
            height: auto;
            display: block;
            border-radius: 6px;
            border: 2px solid transparent;
            box-shadow: 0 4px 12px rgba(0,0,0,0.08);
            transition: all 0.3s ease;
            cursor: zoom-in;
        }

        .content-img.small-size {
            max-width: 60%;
        }

        .content-img:hover {
            transform: translateY(-6px);
            box-shadow: 0 12px 24px rgba(0,0,0,0.15);
            border-color: var(--hover-border-color);
        }

        .caption {
            margin-top: 12px;
            font-size: 0.9rem;
            color: #777;
            text-align: center;
            font-weight: 500;
        }

        /* --- ç¯ç®± (Lightbox) æ ·å¼ --- */
        .lightbox {
            display: none;
            position: fixed;
            z-index: 9999;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            overflow: hidden;
            background-color: rgba(0,0,0,0.85);
            justify-content: center;
            align-items: center;
            backdrop-filter: blur(5px);
        }

        .lightbox-content {
            margin: auto;
            display: block;
            max-width: 90%;
            max-height: 90%;
            border-radius: 4px;
            box-shadow: 0 0 20px rgba(0,0,0,0.5);
            animation: zoomIn 0.3s;
        }

        .lightbox-close {
            position: absolute;
            top: 30px;
            right: 40px;
            color: #f1f1f1;
            font-size: 40px;
            font-weight: bold;
            transition: 0.3s;
            cursor: pointer;
            z-index: 10001;
        }

        .lightbox-close:hover,
        .lightbox-close:focus {
            color: #bbb;
            text-decoration: none;
            cursor: pointer;
        }

        @keyframes zoomIn {
            from {transform:scale(0.8); opacity: 0;}
            to {transform:scale(1); opacity: 1;}
        }

        /* --- é¡µè„šæ ·å¼ --- */
        .bms-footer {
            width: 100%;
            text-align: center;
            background-color: #fff;
            border-top: 1px solid #e0e0e0;
            margin-top: 60px;
            padding-top: 60px;
            padding-bottom: 60px;
        }

        .footer-logo {
            font-size: 1.8rem;
            font-weight: 700;
            color: #000;
            margin-bottom: 25px;
            letter-spacing: 1px;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            border-bottom: none !important;
            padding-bottom: 0 !important;
            display: inline-block;
        }

        .footer-desc p {
            font-size: 1.1rem;
            color: #666;
            margin: 8px 0;
            font-weight: 400;
            line-height: 1.6;
        }

        .footer-copyright {
            margin-top: 45px;
            font-size: 0.95rem;
            color: #bbb;
            font-family: Arial, sans-serif;
        }

        /* å“åº”å¼ */
        @media (max-width: 1400px) {
            h1.main-title { font-size: 1.8rem; }
        }
        @media (max-width: 768px) {
            .lang-switch-wrapper { top: 10px; right: 10px; } /* ç§»åŠ¨ç«¯è¯­è¨€æŒ‰é’®ä½ç½®è°ƒæ•´ */
            nav.sidebar { display: none; }
            main.content { margin-left: 0; padding: 20px; }
            .header-buttons { flex-direction: column; align-items: center; }
            .paper-info-box { padding: 15px; }
            .lightbox-close { top: 15px; right: 20px; font-size: 30px; }
            .content-img { max-width: 95%; }
            .content-img.small-size { max-width: 90%; }
        }
    </style>
</head>
<body>

    <!-- è¯­è¨€åˆ‡æ¢æŒ‰é’® (æ–°å¢) -->
    <div class="lang-switch-wrapper">
        <select id="language-selector" class="lang-select" onchange="changeLanguage(this.value)">
            <option value="zh">ğŸ‡¨ğŸ‡³ ä¸­æ–‡ (ç®€ä½“)</option>
            <option value="en">ğŸ‡ºğŸ‡¸ English</option>
            <option value="fr">ğŸ‡«ğŸ‡· FranÃ§ais</option>
            <option value="de">ğŸ‡©ğŸ‡ª Deutsch</option>
        </select>
    </div>

    <!-- å·¦ä¾§å¯¼èˆªæ  -->
    <nav class="sidebar">
        <h3 data-i18n="nav-title">å¯¼èˆªæ </h3>
        <ul>
            <li><a href="#intro" data-i18n="nav-1">ä¸€ã€BMSçš„éš¾é¢˜</a></li>
            <li><a href="#innovation" data-i18n="nav-2">äºŒã€BMSFormerçš„åˆ›æ–°</a>
                <ul class="sub-menu">
                    <li><a href="#inn-1" data-i18n="nav-2-1">1. åˆ‡é™¤å†—ä½™æ•°æ®</a></li>
                    <li><a href="#inn-2" data-i18n="nav-2-2">2. å±€éƒ¨â€”å…¨å±€èåˆæ³¨æ„åŠ›</a></li>
                    <li><a href="#inn-3" data-i18n="nav-2-3">3. å¤šå°ºåº¦æ·±åº¦å¯åˆ†ç¦»å·ç§¯</a></li>
                </ul>
            </li>
            <li><a href="#dataset" data-i18n="nav-3">ä¸‰ã€æ•°æ®é›†å®æµ‹</a>
                <ul class="sub-menu">
                    <li><a href="#dat-1" data-i18n="nav-3-1">1. ç²¾åº¦å’Œæ³›åŒ–èƒ½åŠ›</a></li>
                    <li><a href="#dat-2" data-i18n="nav-3-2">2. è®¡ç®—æ•ˆç‡å’Œèµ„æºå ç”¨</a></li>
                    <li><a href="#dat-3" data-i18n="nav-3-3">3. é²æ£’æ€§</a></li>
                </ul>
            </li>
            <li><a href="#summary" data-i18n="nav-4">å››ã€æ€»ç»“</a></li>
            <li><a href="#reference" data-i18n="nav-ref">åŸå§‹æ–‡çŒ®</a></li>
        </ul>
    </nav>

    <!-- å³ä¾§ä¸»è¦å†…å®¹ -->
    <main class="content">

        <!-- å¤´éƒ¨åŒºåŸŸ -->
        <header class="article-header content-block">
            <h1 class="main-title">
                <span class="note-tag" data-i18n="tag-note">ã€å­¦ä¹ ç¬”è®°ã€‘</span>
                <span data-i18n="main-title">BMSFormerï¼šé¢å‘èµ„æºå—é™BMSçš„é«˜æ•ˆé”‚ç”µæ± SOHåœ¨çº¿ä¼°ç®—æ¨¡å‹</span>
            </h1>
            <div class="title-divider"></div>
            <div class="header-buttons">
                <a href="https://www.sciencedirect.com/science/article/pii/S0360544224038088?via%3Dihub" target="_blank" class="header-btn">
                    <svg viewBox="0 0 24 24">
                        <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path>
                    </svg>
                    <span data-i18n="btn-link">åŸæ–‡é“¾æ¥ (ScienceDirect)</span>
                </a>
            </div>
            <div class="paper-info-box">
                <p>
                    <strong data-i18n="info-title-label">è®ºæ–‡é¢˜ç›®ï¼š</strong>
                    <span data-i18n="info-title-val">BMSFormer: An efficient deep learning model for online state-of-health estimation of lithium-ion batteries under high-frequency early SOC data with strong correlated single health indicator</span>
                </p>
                <p>
                    <strong data-i18n="info-journal-label">æ¥æºæœŸåˆŠï¼š</strong>
                    <span data-i18n="info-journal-val">Energy ï¼Œ2024</span>
                </p>
                <p>
                    <strong data-i18n="info-keywords-label">å…³é”®è¯ï¼š</strong>
                    <span data-i18n="info-keywords-val">å¥åº·çŠ¶æ€ï¼›é”‚ç¦»å­ç”µæ± ï¼›æ•ˆç‡ä¼°è®¡ï¼›å±€éƒ¨â€”å…¨å±€èåˆæ³¨æ„åŠ›ï¼›æ·±åº¦ç‰¹å¾èåˆ</span>
                </p>
            </div>
        </header>

        <!-- ç¬¬ä¸€ç«  -->
        <section id="intro" class="content-block">
            <h2 data-i18n="sec1-title">ä¸€ã€BMSçš„éš¾é¢˜</h2>
            <p data-i18n="sec1-p1">
               é”‚ç¦»å­ç”µæ± çš„å®‰å…¨ä¸å¯¿å‘½ç®¡ç†æ˜¯å½“ä»Šæ—¶ä»£çš„ä¸€ä¸ªçƒ­ç‚¹ï¼Œå…¶å¥åº·çŠ¶æ€ï¼ˆSOHï¼‰ä¼°ç®—æ˜¯ç”µæ± ç®¡ç†ç³»ç»Ÿï¼ˆBMSï¼‰çš„æ ¸å¿ƒåŠŸèƒ½ä¹‹ä¸€ã€‚åœ¨å®é™…çš„BMSå¼€å‘ä¸­ï¼Œå·¥ç¨‹å¸ˆä»¬é¢ä¸´ç€ä¸‰ä¸ªéš¾é¢˜ï¼š<br>
                <strong>ï¼ˆ1ï¼‰ç®—åŠ›ä¸å­˜å‚¨é™åˆ¶</strong><br>
               åµŒå…¥å¼BMSèŠ¯ç‰‡çš„å­˜å‚¨ç©ºé—´å’Œç®—åŠ›æœ‰é™ï¼Œè€ŒTransformerç­‰æ¨¡å‹å‚æ•°é‡å¤§ï¼ŒèŠ¯ç‰‡æ— æ³•æ‰¿è½½ã€‚<br>
                <strong>ï¼ˆ2ï¼‰å®æ—¶æ€§å’Œç¨³å®šæ€§ä¸è¶³</strong><br>
               è®¸å¤šæ¨¡å‹ç»“æ„å¤æ‚ï¼Œæ¨ç†æ—¶é—´é•¿ï¼Œä¸”å¯¹è¶…å‚æ•°è®¾ç½®æ•æ„Ÿï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶ä¼°ç®—å’Œç¨³å®šæ€§è¦æ±‚ã€‚<br>
                <strong>ï¼ˆ3ï¼‰ç²¾åº¦ä¸è¶³ </strong><br>
               ä¸€äº›æ¨¡å‹æå–çš„å¥åº·æŒ‡æ ‡è¡¨å¾èƒ½åŠ›ä¸è¶³æˆ–æå–äº†å¼±ç›¸å…³æ€§çš„å¥åº·æŒ‡æ ‡ï¼Œå¯¼è‡´ç»“æœç²¾åº¦ä¸è¶³ã€‚
            </p>
            <p data-i18n="sec1-p2">
                é’ˆå¯¹ä»¥ä¸Šé—®é¢˜ï¼Œè¯¥è®ºæ–‡æå‡ºäº†<strong>BMSFormerï¼ˆBattery Management System Transformerï¼‰</strong>è½»é‡çº§æ¨¡å‹ã€‚BMSFormeræ‹¥æœ‰ç€Transformeræ¨¡å‹çš„ç‰¹å¾æå–èƒ½åŠ›ï¼Œåœ¨ä¿è¯ç²¾åº¦çš„å‰æä¸‹ï¼Œé™ä½äº†è®¡ç®—å¤æ‚åº¦å’Œå­˜å‚¨éœ€æ±‚ï¼Œé€‚ç”¨äºèµ„æºå—é™çš„BMSç¯å¢ƒã€‚
            </p>
        </section>

        <!-- ç¬¬äºŒç«  -->
        <section id="innovation" class="content-block">
            <h2 data-i18n="sec2-title">äºŒã€BMSFormerçš„åˆ›æ–°</h2>
            <p data-i18n="sec2-intro">
                BMSFormerä¸æ˜¯ç®€å•çš„Transformeråº”ç”¨ï¼Œè€Œæ˜¯ä¸€ä¸ªé’ˆå¯¹ç”µæ± æ—¶é—´åºåˆ—æ•°æ®ç‰¹æ€§ç»è¿‡æ·±åº¦é‡æ„çš„è½»é‡åŒ–é«˜æ•ˆæ¨¡å‹ã€‚
            </p>

            <div class="img-wrapper">
                <img src="1.jpg" alt="BMSFormer æ¨¡å‹æ•´ä½“æ¶æ„" class="content-img" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex'">
                <span class="caption" data-i18n="fig-1">å›¾1 BMSFormer æ¨¡å‹æ•´ä½“æ¶æ„</span>
            </div>

            <div id="inn-1">
                <h3 data-i18n="sec2-1-title">1. åˆ‡é™¤å†—ä½™æ•°æ®</h3>
                <p data-i18n="sec2-1-p1">
                    ä¼ ç»Ÿçš„SOHä¼°ç®—éœ€è¦å®Œæ•´çš„å……æ”¾ç”µå¾ªç¯æ•°æ®ï¼Œä½†è¿™åœ¨å®é™…åº”ç”¨ä¸­å¾ˆéš¾å®ç°ã€‚BMSFormeræå‡ºäº†ä¸€ç§ç²¾ç®€çš„ç‰¹å¾æå–ç­–ç•¥ï¼š<br>
                     <strong>ï¼ˆ1ï¼‰é”å®šé«˜é¢‘åŒºé—´ </strong><br>
                    é€‰å–ç”µæ± æ—¥å¸¸è¿è¡Œæœ€é¢‘ç¹å‡ºç°çš„ç”µå‹åŒºé—´ï¼Œå³ 3.8V è‡³ 4.2V å……ç”µåŒºé—´å’Œ 3.8V è‡³ 3.4V æ”¾ç”µåŒºé—´ã€‚<br>
                     <strong>ï¼ˆ2ï¼‰å•å¥åº·å› å­ </strong><br>
                    é€šè¿‡æ»‘åŠ¨çª—å£æŠ€æœ¯ï¼Œé€æ­¥ç¼©å°çª—å£å¤§å°å’Œæ­¥é•¿ï¼Œç­›é€‰å‡ºä¸SOHç›¸å…³æ€§æœ€å¼ºçš„å•ä¸€å¥åº·å› å­ï¼ˆHIsï¼‰ï¼Œå…¶çš®å°”é€Šï¼ˆPCCï¼‰ç›¸å…³ç³»æ•°å¤§äº0.99ã€‚<br>
                    åœ¨æ­¤ç­–ç•¥ä¸‹ï¼ŒBMSFormeråªéœ€æ•æ‰åˆ°è¿™çŸ­çŸ­å‡ åˆ†é’Ÿçš„æ•°æ®ç‰‡æ®µï¼Œé€šè¿‡å¼ºç›¸å…³çš„å•å¥åº·å› å­ï¼Œå¿«é€Ÿåˆ¤æ–­ç”µæ± å¥åº·åº¦ã€‚
                </p>
                <div class="img-wrapper">
                    <img src="2.jpg" alt="å›¾2 é€‰å®šå……ç”µåŒºé—´å†…é€‰å®šå¥åº·æŒ‡æ ‡ï¼ˆHIï¼‰çš„æå–æµç¨‹" class="content-img small-size" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex'">
                    <span class="caption" data-i18n="fig-2">å›¾2 é€‰å®šå……ç”µåŒºé—´å†…é€‰å®šå¥åº·æŒ‡æ ‡ï¼ˆHIï¼‰çš„æå–æµç¨‹</span>
                </div>
            </div>

            <div id="inn-2">
                <h3 data-i18n="sec2-2-title">2. å±€éƒ¨â€”å…¨å±€èåˆæ³¨æ„åŠ›æœºåˆ¶ (LGFA)</h3>
                <p data-i18n="sec2-2-p1">
                    ä¼ ç»Ÿçš„Transformeræ¨¡å‹é‡‡ç”¨Softmaxæ³¨æ„åŠ›æœºåˆ¶ï¼Œå…¶è®¡ç®—å¤æ‚åº¦éšåºåˆ—é•¿åº¦å‘ˆäºŒæ¬¡æ–¹å¢é•¿ï¼Œå¯¹å¤§è§„æ¨¡åºåˆ—åº”ç”¨æ—¶è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚BMSFormerè®¾è®¡äº†<strong> LGFA (Local-Global Fusion Attention) </strong>æ¨¡å—æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚<br>
                     <strong>ï¼ˆ1ï¼‰ä»æŒ‡æ•°åˆ°çº¿æ€§ </strong><br>
                    åˆ©ç”¨ReLUçº¿æ€§æ³¨æ„åŠ›æœºåˆ¶æ›¿ä»£ä¼ ç»Ÿçš„Softmaxï¼Œå°†è®¡ç®—å¤æ‚åº¦é™ä½ä¸ºçº¿æ€§ã€‚<br>
                     <strong>ï¼ˆ2ï¼‰å±€éƒ¨ç‰¹å¾å¢å¼º </strong><br>
                    çº¿æ€§æ³¨æ„åŠ›å®¹æ˜“ä¸¢å¤±ç»†èŠ‚ã€‚LGFAæ¨¡å—å¼•å…¥äº†æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆDSConvï¼‰ï¼Œä½¿æ¨¡å‹æ—¢èƒ½æ•æ‰å…¨å±€å˜åŒ–è¶‹åŠ¿ï¼Œåˆä¿ç•™äº†å¯¹å±€éƒ¨ç”µå‹æ³¢åŠ¨ç‰¹å¾çš„æ•æ„Ÿåº¦ã€‚
                </p>
                <div class="img-wrapper">
                    <img src="3.jpg" alt="LGFAæ¶æ„å›¾" class="content-img" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex'">
                   <span class="caption" data-i18n="fig-3">å›¾3 ä¸åŒæ³¨æ„åŠ›æœºåˆ¶å¯¹æ¯”ï¼š(a) ä¼ ç»Ÿ Softmax æ³¨æ„åŠ›æœºåˆ¶ï¼›(b) ä¼ ç»Ÿçº¿æ€§æ³¨æ„åŠ›æœºåˆ¶ï¼›(c) å±€éƒ¨-å…¨å±€èåˆæ³¨æ„åŠ›ï¼ˆLGFAï¼‰æ¨¡å—</span>
                </div>
            </div>

            <div id="inn-3">
                <h3 data-i18n="sec2-3-title">3. å¤šå°ºåº¦æ·±åº¦å¯åˆ†ç¦»å·ç§¯ (DSConv)</h3>
                <p data-i18n="sec2-3-p1">
                    BMSFormeré‡‡ç”¨<strong>æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆDepthwise Separable Convolutionï¼‰</strong>ä»£æ›¿ä¼ ç»Ÿå·ç§¯ï¼Œä½¿æ¨¡å‹æ›´è½»é‡åŒ–ã€‚<br>
                     <strong>ï¼ˆ1ï¼‰DSConv-S </strong><br>
                    é‡‡ç”¨ 2 å€è¾“å…¥é€šé“æ‰©å±•å› å­ï¼Œåº”ç”¨ 1Ã—3 æ·±åº¦å·ç§¯æ ¸å°ºå¯¸ï¼Œè´Ÿè´£æå–çŸ­æœŸã€ç»†å¾®çš„ç‰¹å¾å˜åŒ–ã€‚<br>
                     <strong>ï¼ˆ2ï¼‰DSConv-L </strong><br>
                    é‡‡ç”¨ 3 å€è¾“å…¥é€šé“æ‰©å±•å› å­ï¼Œåº”ç”¨ 1Ã—31 æ·±åº¦å·ç§¯æ ¸å°ºå¯¸ï¼Œè´Ÿè´£æå–é•¿æœŸã€æ•´ä½“çš„é€€åŒ–è¶‹åŠ¿ã€‚
                </p>
                <div class="img-wrapper">
                    <img src="4.jpg" alt="DSConvç¤ºæ„å›¾" class="content-img" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex'">
                    <span class="caption" data-i18n="fig-4">å›¾4 åŸºæœ¬ç»“æ„ç¤ºæ„å›¾ï¼š(a) æ ‡å‡†å·ç§¯ï¼›(b) æ ‡å‡†æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼›(c) DSConv-Sæ¨¡å—ï¼›(d) DSConv-Læ¨¡å—ã€‚</span>
                </div>
            </div>
        </section>

        <!-- ç¬¬ä¸‰ç«  -->
        <section id="dataset" class="content-block">
            <h2 data-i18n="sec3-title">ä¸‰ã€æ•°æ®é›†å®æµ‹</h2>
            <p data-i18n="sec3-intro">
                ä½œè€…ä½¿ç”¨äº†ä¸‰ä¸ªå…¬å¼€æ•°æ®é›†ï¼ˆOxfordã€NASAã€CALCEï¼‰å¯¹äº”ç§æ¨¡å‹ï¼ˆBMSFormerã€CNN-Transformerã€CNN-LSTMã€Transformer ã€LSTMï¼‰è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œé€‰ç”¨äº”ç§è¯„ä¼°æŒ‡æ ‡ï¼ˆå¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ã€å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®ï¼ˆMAPEï¼‰ã€å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰ã€å†³å®šç³»æ•°ï¼ˆR2ï¼‰å’Œå¹³å‡å‡æ–¹æ ¹è¯¯å·®ï¼ˆARMSEï¼‰ï¼‰è¯„ä¼°æ€§èƒ½ï¼Œæ¶µç›–äº†ä¸åŒçš„ç”µæ± ææ–™ï¼ˆLCOã€NCAã€NCOï¼‰å’Œä¸åŒç”µæ± å½¢æ€ï¼ˆè½¯åŒ…ã€åœ†æŸ±ã€æ–¹å½¢ï¼‰ã€‚
            </p>
            <div id="dat-1">
                <h3 data-i18n="sec3-1-title">1. ç²¾åº¦å’Œæ³›åŒ–èƒ½åŠ›</h3>
                <p data-i18n="sec3-1-p1">
                    åœ¨Oxfordæ•°æ®é›†ä¸Šï¼ŒBMSFormerçš„å¹³å‡RMSEä»…ä¸º <strong>0.0031</strong>ã€‚ç›¸æ¯”å…¶ä»–å››ä¸ªæ¨¡å‹ï¼Œå¹³å‡MAEé™ä½å¹…åº¦åœ¨14.81% ~ 73.56% ä¹‹é—´ï¼Œå¹³å‡ MAPEé™ä½å¹…åº¦åœ¨20.00% ~ 76.32% ä¹‹é—´ã€‚
                    åœ¨NASAå’ŒCALCEæ•°æ®é›†ä¸Šï¼Œé¢å¯¹å‡ºç°çš„å®¹é‡å†ç”Ÿï¼ˆCapacity Regenerationï¼‰ç°è±¡æ—¶ï¼ŒBMSFormerå±•ç°äº†æ›´å¥½çš„è·Ÿè¸ªèƒ½åŠ›ï¼Œè¯¯å·®æ³¢åŠ¨æ›´å°ï¼Œé¢„æµ‹æ›²çº¿æœ€è´´åˆçœŸå®å€¼ã€‚å…¶å¹³å‡ MAE é™ä½å¹…åº¦åœ¨23.67% ~ 47.90% ä¹‹é—´ï¼Œå¹³å‡ MAPEé™ä½å¹…åº¦åœ¨ 20.42% ~ 53.71% ä¹‹é—´ã€‚
                </p>
            </div>

            <div id="dat-2">
                <h3 data-i18n="sec3-2-title">2. è®¡ç®—æ•ˆç‡å’Œèµ„æºå ç”¨</h3>
                <p data-i18n="sec3-2-p1">
                    åœ¨ç›¸åŒçš„è®­ç»ƒæ¡ä»¶ä¸‹ï¼ŒBMSFormeræ¨¡å‹å¤§å°ä»…ä¸º <strong>36.37 KB</strong>ï¼Œç›¸æ¯”äºç²¾åº¦è¡¨ç°è¾ƒå¥½çš„CNN-Transformerï¼ˆ47.10 KBï¼‰å’ŒTransformerï¼ˆ39.48KBï¼‰ï¼Œå®ƒæ›´é€‚åˆåµŒå…¥èŠ¯ç‰‡æœ‰é™çš„å­˜å‚¨ç©ºé—´ä¸­ï¼Œå¹¶ä¸”BMSFormer å®ç°äº†æœ€çŸ­çš„è®­ç»ƒæ—¶é—´ 19.83sã€‚
                </p>
                <div class="img-wrapper">
                    <img src="5.jpg" alt="LGFAå®æµ‹ç»“æœå›¾" class="content-img" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex'">
                    <span class="caption" data-i18n="tab-1">è¡¨1 ç›¸åŒå’Œæœ€ä¼˜é…ç½®ä¸‹æ¨¡å‹çš„ç»¼åˆæ€§èƒ½</span>
                </div>
            </div>

            <div id="dat-3">
                <h3 data-i18n="sec3-3-title">3. é²æ£’æ€§</h3>
                <p data-i18n="sec3-3-p1">
                    ä½œè€…å¯¹äº”ç§æ¨¡å‹åˆ†åˆ«åœ¨è®­ç»ƒé›†ä¸Šä½¿ç”¨ 384 ç§ä¸åŒçš„è¶…å‚æ•°ç»„åˆè¿›è¡Œè®­ç»ƒå’ŒéªŒè¯ã€‚è¶…å‚æ•°åŒ…æ‹¬è¿­ä»£æ¬¡æ•°ã€å­¦ä¹ ç‡ã€å—æ•°ã€å±‚æ•°ã€ç¨ å¯†ç»´åº¦ã€åµŒå…¥ç»´åº¦ã€‚
                </p>
                <div class="img-wrapper">
                    <img src="6.jpg" alt="DSConvå®æµ‹åˆ†æå›¾" class="content-img" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex'">
                    <span class="caption" data-i18n="tab-2">è¡¨2 è¶…å‚æ•°ç»„åˆ</span>
                </div>
                <p data-i18n="sec3-3-p2">
                    BMSFormeråœ¨ä¸åŒè¶…å‚æ•°ç»„åˆä¸‹å‡è¡¨ç°å‡ºç¨³å¥çš„æ€§èƒ½å’Œç²¾åº¦ï¼Œä¸”æœ‰ 41 ç§ç»„åˆçš„é¢„æµ‹æ¨¡å‹R2å€¼è¶…è¿‡ 0.98ï¼Œ43.23% çš„ç»„åˆR2å€¼å¤§äº 0.9ï¼Œè¿˜å®ç°äº†æœ€é«˜çš„R2å€¼0.9892ã€‚ç»“æœè¡¨æ˜è¯¥æ¨¡å‹å¯¹è¶…å‚æ•°ä¸æ•æ„Ÿï¼Œåœ¨å®é™…å·¥ç¨‹åº”ç”¨ä¸­æ›´æ–¹ä¾¿è°ƒè¯•ã€‚
                </p>
                <div class="img-wrapper">
                    <img src="7.jpg" alt="DSConvå®æµ‹åˆ†æå›¾" class="content-img small-size" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex'">
                    <span class="caption" data-i18n="fig-5">å›¾5 ä¸åŒæ¨¡å‹åŠè¶…å‚æ•°ç»„åˆä¸‹çš„æ•´ä½“éªŒè¯ç»“æœ</span>
                </div>
            </div>
        </section>

        <!-- ç¬¬å››ç«  -->
        <section id="summary" class="content-block">
            <h2 data-i18n="sec4-title">å››ã€æ€»ç»“</h2>
            <p data-i18n="sec4-p1">
                BMSFormeræ¨¡å‹é€šè¿‡å¼•å…¥å±€éƒ¨-å…¨å±€èåˆæ³¨æ„åŠ›æœºåˆ¶ (LGFA)å’Œå¤šå°ºåº¦æ·±åº¦å¯åˆ†ç¦»å·ç§¯ (DSConv)ï¼Œè‡´åŠ›äºå°†Transformerçš„å¼ºå¤§èƒ½åŠ›æµ“ç¼©åˆ°å¾®å‹æ¨¡å‹ä¸­ï¼Œå¯¹äºè§£å†³å¦‚ä½•åœ¨ä½ç®—åŠ›å¹³å°ä¸Šå®ç°é«˜ç²¾åº¦ã€ä½å»¶æ—¶çš„SOHä¼°ç®—è¿™ä¸€é—®é¢˜æä¾›äº†ä¸€ä¸ªå¤‡é€‰é€”å¾„ã€‚
            </p>
        </section>

        <!-- åŸå§‹æ–‡çŒ® -->
        <section id="reference" class="content-block">
            <h2 data-i18n="ref-title">åŸå§‹æ–‡çŒ®</h2>
            <p>
                Li X, Zhao M, Zhong S, et al. BMSFormer: An efficient deep learning model for online state-of-health estimation of lithium-ion batteries under high-frequency early SOC data with strong correlated single health indicator[J]. Energy, 2024, 313: 134030.
            </p>
        </section>

        <!-- é¡µè„šåŒºåŸŸ -->
        <footer class="bms-footer">
            <h2 class="footer-logo">BMSFormer</h2>

            <div class="footer-desc">
                <p data-i18n="footer-slogan">é¢å‘èµ„æºå—é™BMSçš„é«˜æ•ˆæ¨¡å‹</p>
                <p data-i18n="footer-tech">å±€éƒ¨â€”å…¨å±€èåˆæ³¨æ„åŠ›æœºåˆ¶ &bull; æ·±åº¦ç‰¹å¾èåˆ</p>
            </div>

            <div class="footer-copyright">
                &copy; Â· 2024 Â· BMSFormer
            </div>
        </footer>
    </main>

    <!-- ç¯ç®±å®¹å™¨ -->
    <div id="lightbox" class="lightbox">
        <span class="lightbox-close">&times;</span>
        <img class="lightbox-content" id="lightbox-img">
    </div>

    <script>
    // 1. ç›®å½•å¹³æ»‘æ»šåŠ¨ä»£ç 
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener('click', function (e) {
            // å¦‚æœæ˜¯è¯­è¨€åˆ‡æ¢çš„ hashï¼ˆå¦‚ #us, #frï¼‰ï¼Œä¸è¿›è¡Œæ»šåŠ¨å¤„ç†
            const href = this.getAttribute('href');
            if (['#us', '#en', '#fr', '#de', '#zh'].includes(href)) return;

            e.preventDefault();
            const target = document.querySelector(href);
            if (target) {
                target.scrollIntoView({
                    behavior: 'smooth'
                });
            }
        });
    });

    // 2. ç¯ç®± (Lightbox) é€»è¾‘ä»£ç 
    const lightbox = document.getElementById('lightbox');
    const lightboxImg = document.getElementById('lightbox-img');
    const closeBtn = document.querySelector('.lightbox-close');
    const images = document.querySelectorAll('.content-img');

    images.forEach(img => {
        img.addEventListener('click', function() {
            if (this.style.display === 'none') return;
            lightbox.style.display = "flex";
            lightboxImg.src = this.src;
        });
    });

    closeBtn.onclick = function() { lightbox.style.display = "none"; }
    lightbox.onclick = function(e) { if (e.target === lightbox) lightbox.style.display = "none"; }
    document.addEventListener('keydown', function(e) {
        if (e.key === "Escape" && lightbox.style.display === "flex") {
            lightbox.style.display = "none";
        }
    });

    // 3. å¤šè¯­è¨€ç¿»è¯‘æ•°æ®
    const translations = {
        // ... (æ­¤å¤„ä¿æŒæ‚¨åŸæœ‰çš„ç¿»è¯‘æ•°æ®å†…å®¹ä¸å˜ï¼Œå¤ªé•¿çœç•¥ä»¥èŠ‚çœç©ºé—´) ...
        // è¯·ç¡®ä¿ä¿ç•™å®Œæ•´çš„ translations å¯¹è±¡
        // ================== è‹±è¯­ English ==================
        "en": {
            "nav-title": "Navigation",
            "nav-1": "I. Challenges of BMS",
            "nav-2": "II. Innovation of BMSFormer",
            "nav-2-1": "1. Pruning Redundant Data",
            "nav-2-2": "2. Local-Global Fusion Attention (LGFA) Mechanism",
            "nav-2-3": "3. Multi-Scale Depthwise Separable Convolution (DSConv)",
            "nav-3": "III. Dataset Evaluation",
            "nav-3-1": "1. Accuracy and Generalization Ability",
            "nav-3-2": "2. Computational Efficiency and Resource Consumption",
            "nav-3-3": "3. Robustness",
            "nav-4": "IV. Conclusion",
            "nav-ref": "Original Reference",
            "tag-note": "[Study Note]",
            "main-title": "BMSFormer: An Efficient Online Li-ion Battery SOH Estimation Model for Resource-Constrained BMS",
            "btn-link": "Original Paper (ScienceDirect)",
            "info-title-label": "Title:",
            "info-title-val": "BMSFormer: An efficient deep learning model for online state-of-health estimation of lithium-ion batteries under high-frequency early SOC data with strong correlated single health indicator",
            "info-journal-label": "Journal:",
            "info-journal-val": "Energy, 2024",
            "info-keywords-label": "Keywords:",
            "info-keywords-val": "State of health (SOH); Lithium-ion battery; Efficient estimation; Local-global fusion attention; Deep feature fusion",
            "sec1-title": "I. Challenges of BMS",
            "sec1-p1": "Safety and lifespan management of lithium-ion batteries have become critical focal points, with State of Health (SOH) estimation acting as a core function of the Battery Management System (BMS). In practical BMS development, engineers face three primary challenges:<br><strong>(1) Computational and Storage Constraints</strong><br>Embedded BMS chips possess limited storage capacity and computational power. Conversely, models like the Transformer involve a vast number of parameters, making them too heavy for such chips to accommodate.<br><strong>(2) Insufficient Real-time Performance and Stability</strong><br>Many models feature complex architectures and long inference times. Furthermore, they are often sensitive to hyperparameter settings, making it difficult to meet the requirements for real-time estimation and operational stability.<br><strong>(3) Inadequate Accuracy</strong><br>Some models rely on health indicators (HIs) with insufficient representational capability or extract HIs that are only weakly correlated with battery health, resulting in compromised estimation accuracy.",
            "sec1-p2": "To address these issues, this paper proposes the lightweight <strong>BMSFormer (Battery Management System Transformer)</strong> model. BMSFormer retains the feature extraction capabilities of the Transformer model while effectively reducing computational complexity and storage requirements without compromising accuracy, making it suitable for resource-constrained BMS environments.",
            "sec2-title": "II. Innovation of BMSFormer",
            "sec2-intro": "BMSFormer is not merely a simple application of the Transformer; rather, it is a lightweight, high-efficiency model that has been deeply reconstructed to align with the characteristics of battery time-series data.",
            "fig-1": "Fig.1 BMSFormer Model Framework: (a) Local-Global Fusion Attention (LGFA) module; (b) BMSFormer block; (c) DSConv-L module; (d) Core structure of BMSFormer.",
            "sec2-1-title": "1. Pruning Redundant Data",
            "sec2-1-p1": "Traditional SOH estimation requires complete charge-discharge cycle data, which is often impractical in real-world applications. BMSFormer proposes a streamlined feature extraction strategy:<br><strong>(1) Targeting High-Frequency Intervals</strong><br>The model selects voltage intervals that occur most frequently during daily battery operation, specifically the 3.8V to 4.2V charging interval and the 3.8V to 3.4V discharging interval.<br><strong>(2) Single Health Indicator </strong><br>Using a sliding window technique with progressively reducing window sizes and step lengths, the model screens for the single Health Indicator (HIs) most strongly correlated with SOH, achieving a Pearson Correlation Coefficient (PCC) greater than 0.99.<br>Under this strategy, BMSFormer only needs to capture these brief data fragments spanning a few minutes to rapidly assess battery health via the strongly correlated single HI.",
            "fig-2": "Fig.2 Extraction process of the selected Health Indicator (HI) within the chosen charging interval.",
            "sec2-2-title": "2. Local-Global Fusion Attention (LGFA) Mechanism",
            "sec2-2-p1": "Traditional Transformer models utilize the Softmax attention mechanism, where computational complexity grows quadratically with sequence length, leading to prohibitive computational costs for large-scale sequences. BMSFormer introduces the <strong>Local-Global Fusion Attention (LGFA)</strong> module to address this issue.<br><strong>(1) From Exponential to Linear</strong><br>By replacing the traditional Softmax with a ReLU linear attention mechanism, the computational complexity is reduced to a linear scale.<br><strong>(2) Local Feature Enhancement</strong><br>Linear attention mechanisms are prone to missing details. The LGFA module incorporates Depthwise Separable Convolution (DSConv), enabling the model to capture global evolutionary trends while retaining sensitivity to local voltage fluctuation features.",
            "fig-3": "Fig.3 Comparison of different attention mechanisms: (a) Traditional Softmax attention; (b) Traditional linear attention; (c) Local-Global Fusion Attention (LGFA) module.",
            "sec2-3-title": "3. Multi-Scale Depthwise Separable Convolution (DSConv)",
            "sec2-3-p1": "BMSFormer employs <strong>Depthwise Separable Convolution (DSConv)</strong> instead of standard convolution to render the model more lightweight.<br><strong>(1) DSConv-S</strong><br>Utilizes a 2x input channel expansion factor and a 1Ã—3 depthwise convolution kernel size, responsible for extracting short-term, subtle feature variations.<br><strong>(2) DSConv-L</strong><br>Utilizes a 3x input channel expansion factor and a 1Ã—31 depthwise convolution kernel size, responsible for extracting long-term, overall degradation trends.",
            "fig-4": "Fig.4 Schematic of basic structures: (a) Standard convolution; (b) Standard depthwise separable convolution; (c) DSConv-S module; (d) DSConv-L module.",
            "sec3-title": "III. Dataset Evaluation",
            "sec3-intro": "The authors conducted a comprehensive evaluation of five models (BMSFormer, CNN-Transformer, CNN-LSTM, Transformer, and LSTM) using three public datasets (Oxford, NASA, and CALCE). Performance was assessed using five metrics: Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), Root Mean Square Error (RMSE), Coefficient of Determination (R2), and Average Root Mean Square Error (ARMSE). The study covered various battery materials (LCO, NCA, NCO) and form factors (pouch, cylindrical, prismatic).",
            "sec3-1-title": "1. Accuracy and Generalization Ability",
            "sec3-1-p1": "On the Oxford dataset, the average RMSE of BMSFormer was only<strong> 0.0031</strong>. Compared to the other four models, the average MAE reduction ranged from 14.81% to 73.56%, and the average MAPE reduction ranged from 20.00% to 76.32%.On the NASA and CALCE datasets, when encountering the phenomenon of capacity regeneration, BMSFormer demonstrated superior tracking capability with smaller error fluctuations, producing prediction curves that most closely matched the ground truth. Its average MAE reduction ranged from 23.67% to 47.90%, and average MAPE reduction ranged from 20.42% to 53.71%.",
            "sec3-2-title": "2. Computational Efficiency and Resource Consumption",
            "sec3-2-p1": "Under identical training conditions, the BMSFormer model size is only <strong>36.37 KB</strong>. Compared to CNN-Transformer (47.10 KB) and Transformer (39.48 KB), which performed relatively well in accuracy, BMSFormer is more suitable for the limited storage space of embedded chips. Additionally, BMSFormer achieved the shortest training time of 19.83 seconds.",
            "tab-1": "Table 1 Comprehensive performance of models under identical and optimal configurations.",
            "sec3-3-title": "3. Robustness",
            "sec3-3-p1": "The authors trained and validated the five models on the training set using 384 different hyperparameter combinations. These hyperparameters included epoch number, learning rate, number of blocks, number of layers, dense dimension, and embedding dimension.",
            "tab-2": "Table 2 Hyperparameter combinations.",
            "sec3-3-p2": "BMSFormer exhibited robust performance and accuracy across different hyperparameter combinations. Specifically, 41 combinations yielded prediction models with an R2 value exceeding 0.98, and 43.23% of the combinations had an R2 value greater than 0.9. It also achieved the highest R2 value of 0.9892. These results indicate that the model is insensitive to hyperparameters, making it easier to tune in practical engineering applications.",
            "fig-5": "Fig.5 Overall validation results under different models and hyperparameter combinations.",
            "sec4-title": "IV. Conclusion",
            "sec4-p1": "By introducing the Local-Global Fusion Attention (LGFA) mechanism and multi-scale Depthwise Separable Convolution (DSConv), the BMSFormer model aims to condense the powerful capabilities of the Transformer into a compact model. This provides an alternative pathway for solving the problem of achieving high-precision, low-latency SOH estimation on low-computational-power platforms.",
            "ref-title": "Original Reference",
            "footer-slogan": "Efficient Model for Resource-Constrained BMS",
            "footer-tech": "Local-Global Fusion Attention &bull; Deep Feature Fusion"
        },
        // ================== æ³•è¯­ FranÃ§ais ==================
        "fr": {
            "nav-title": "Navigation",
            "nav-1": "I. Les dÃ©fis du BMS",
            "nav-2": "II. Les innovations du BMSFormer",
            "nav-2-1": "1. Ã‰lagage des donnÃ©es redondantes",
            "nav-2-2": "2. MÃ©canisme d'Attention de Fusion Locale-Globale (LGFA)",
            "nav-2-3": "3. Convolution SÃ©parable en Profondeur (DSConv) Multi-Ã©chelle",
            "nav-3": "III. Ã‰valuation empirique sur les ensembles de donnÃ©es",
            "nav-3-1": "1. PrÃ©cision et capacitÃ© de gÃ©nÃ©ralisation",
            "nav-3-2": "2. EfficacitÃ© de calcul et consommation de ressources",
            "nav-3-3": "3. Robustesse",
            "nav-4": "IV. Conclusion",
            "nav-ref": "RÃ©fÃ©rence originale",
            "tag-note": "[Note d'Ã©tude]",
            "main-title": "BMSFormer : Un modÃ¨le efficace d'estimation en ligne du SOH pour les BMS Ã  ressources limitÃ©es",
            "btn-link": "Lien original (ScienceDirect)",
            "info-title-label": "Titre de l'article :",
            "info-title-val": "BMSFormer: An efficient deep learning model for online state-of-health estimation of lithium-ion batteries under high-frequency early SOC data with strong correlated single health indicator",
            "info-journal-label": "Journal :",
            "info-journal-val": "Energy, 2024",
            "info-keywords-label": "Mots-clÃ©s :",
            "info-keywords-val": "Ã‰tat de santÃ© (SOH) ; Batterie lithium-ion ; Estimation de l'efficacitÃ© ; Attention de fusion locale-globale ; Fusion de caractÃ©ristiques profondes",
            "sec1-title": "I. Les dÃ©fis du BMS",
            "sec1-p1": "La sÃ©curitÃ© et la gestion de la durÃ©e de vie des batteries lithium-ion sont des sujets brÃ»lants Ã  l'heure actuelle, l'estimation de leur Ã©tat de santÃ© (SOH) Ã©tant l'une des fonctions principales du systÃ¨me de gestion de batterie (BMS). Dans le dÃ©veloppement rÃ©el de BMS, les ingÃ©nieurs sont confrontÃ©s Ã  trois dÃ©fis majeurs :<br><strong>(1) Contraintes de puissance de calcul et de stockage</strong><br>Les puces BMS embarquÃ©es disposent d'un espace de stockage et d'une puissance de calcul limitÃ©s. En revanche, des modÃ¨les tels que le Transformer impliquent un grand nombre de paramÃ¨tres, ce qui les rend trop lourds pour Ãªtre supportÃ©s par ces puces.<br><strong>(2) Performance temps rÃ©el et stabilitÃ© insuffisantes</strong><br>De nombreux modÃ¨les prÃ©sentent des architectures complexes et des temps d'infÃ©rence longs. De plus, ils sont souvent sensibles aux rÃ©glages des hyperparameters, ce qui rend difficile le respect des exigences en matiÃ¨re d'estimation en temps rÃ©el et de stabilitÃ© opÃ©rationnelle.<br><strong>(3) PrÃ©cision insuffisante</strong><br>Certains modÃ¨les s'appuient sur des indicateurs de santÃ© (HIs) ayant une capacitÃ© de reprÃ©sentation insuffisante ou extraient des indicateurs faiblement corrÃ©lÃ©s, ce qui entraÃ®ne une prÃ©cision insuffisante des rÃ©sultats.",
            "sec1-p2": "Pour rÃ©pondre Ã  ces problÃ¨mes, cet article propose le modÃ¨le lÃ©ger <strong>BMSFormer (Battery Management System Transformer)</strong>. Le BMSFormer conserve les capacitÃ©s d'extraction de caractÃ©ristiques du modÃ¨le Transformer tout en rÃ©duisant efficacement la complexitÃ© de calcul et les exigences de stockage sans sacrifier la prÃ©cision, ce qui le rend adaptÃ© aux environnements BMS Ã  ressources limitÃ©es.",
            "sec2-title": "II. Les innovations du BMSFormer",
            "sec2-intro": "Le BMSFormer n'est pas une simple application du Transformer ; il s'agit plutÃ´t d'un modÃ¨le lÃ©ger et efficace qui a Ã©tÃ© profondÃ©ment reconstruit pour s'aligner sur les caractÃ©ristiques des donnÃ©es de sÃ©ries temporelles de la batterie.",
            "fig-1": "Fig.1 Cadre du modÃ¨le BMSFormer : (a) Module d'Attention de Fusion Locale-Globale (LGFA) ; (b) Bloc BMSFormer ; (c) Module DSConv-L ; (d) Structure centrale du BMSFormer.",
            "sec2-1-title": "1. Ã‰lagage des donnÃ©es redondantes",
            "sec2-1-p1": "L'estimation traditionnelle du SOH nÃ©cessite des donnÃ©es complÃ¨tes de cycle de charge-dÃ©charge, ce qui est souvent difficile Ã  rÃ©aliser dans les applications rÃ©elles. Le BMSFormer propose une stratÃ©gie d'extraction de caractÃ©ristiques rationalisÃ©e :<br><strong>(1) Ciblage des intervalles Ã  haute frÃ©quence</strong><br>Le modÃ¨le sÃ©lectionne les intervalles de tension qui apparaissent le plus frÃ©quemment lors du fonctionnement quotidien de la batterie, Ã  savoir l'intervalle de charge de 3,8 V Ã  4,2 V et l'intervalle de dÃ©charge de 3,8 V Ã  3,4 V.<br><strong>(2) Indicateur de santÃ© unique</strong>En utilisant une technique de fenÃªtre glissante (sliding window) avec une rÃ©duction progressive de la taille de la fenÃªtre et du pas, le modÃ¨le sÃ©lectionne l'indicateur de santÃ© (HIs) unique le plus fortement corrÃ©lÃ© au SOH, atteignant un coefficient de corrÃ©lation de Pearson (PCC) supÃ©rieur Ã  0,99.<br>GrÃ¢ce Ã  cette stratÃ©gie, le BMSFormer n'a besoin de capturer que ces courts fragments de donnÃ©es de quelques minutes pour Ã©valuer rapidement la santÃ© de la batterie via l'indicateur unique fortement corrÃ©lÃ©.",
            "fig-2": "Fig.2 Processus d'extraction de l'indicateur de santÃ© (HI) sÃ©lectionnÃ© dans l'intervalle de charge choisi.",
            "sec2-2-title": "2. MÃ©canisme d'Attention de Fusion Locale-Globale (LGFA)",
            "sec2-2-p1": "Les modÃ¨les Transformer traditionnels utilisent le mÃ©canisme d'attention Softmax, dont la complexitÃ© de calcul croÃ®t de maniÃ¨re quadratique avec la longueur de la sÃ©quence, entraÃ®nant des coÃ»ts de calcul prohibitifs pour les sÃ©quences Ã  grande Ã©chelle. Le BMSFormer introduit le module <strong>LGFA (Local-Global Fusion Attention)</strong> pour rÃ©soudre ce problÃ¨me.<br><strong>(1) De l'exponentiel au linÃ©aire</strong><br>En remplaÃ§ant le Softmax traditionnel par un mÃ©canisme d'attention linÃ©aire ReLU, la complexitÃ© de calcul est rÃ©duite Ã  une Ã©chelle linÃ©aire.<br><strong>(2) AmÃ©lioration des caractÃ©ristiques locales</strong><br>Les mÃ©canismes d'attention linÃ©aire ont tendance Ã  perdre des dÃ©tails. Le module LGFA intÃ¨gre la convolution sÃ©parable en profondeur (DSConv), permettant au modÃ¨le de capturer les tendances Ã©volutives globales tout en conservant une sensibilitÃ© aux caractÃ©ristiques locales de fluctuation de tension.",
            "fig-3": "Fig.3 Comparaison des diffÃ©rents mÃ©canismes d'attention : (a) MÃ©canisme d'attention Softmax traditionnel ; (b) MÃ©canisme d'attention linÃ©aire traditionnel ; (c) Module d'Attention de Fusion Locale-Globale (LGFA).",
            "sec2-3-title": "3. Convolution SÃ©parable en Profondeur (DSConv) Multi-Ã©chelle",
            "sec2-3-p1": "Le BMSFormer utilise la <strong>convolution sÃ©parable en profondeur (DSConv)</strong> au lieu de la convolution standard pour rendre le modÃ¨le plus lÃ©ger.<br><strong>(1) DSConv-S</strong><br>Utilise un facteur d'expansion des canaux d'entrÃ©e de 2x et une taille de noyau de convolution en profondeur de 1Ã—3, responsable de l'extraction des variations de caractÃ©ristiques subtiles et Ã  court terme.<br><strong>(2) DSConv-L</strong><br>Utilise un facteur d'expansion des canaux d'entrÃ©e de 3x et une taille de noyau de convolution en profondeur de 1Ã—31, responsable de l'extraction des tendances de dÃ©gradation globales et Ã  long terme.",
            "fig-4": "Fig.4 SchÃ©ma des structures de base : (a) Convolution standard ; (b) Convolution sÃ©parable en profondeur standard ; (c) Module DSConv-S ; (d) Module DSConv-L.",
            "sec3-title": "III. Ã‰valuation empirique sur les ensembles de donnÃ©es",
            "sec3-intro": "Les auteurs ont menÃ© une Ã©valuation complÃ¨te de cinq modÃ¨les (BMSFormer, CNN-Transformer, CNN-LSTM, Transformer et LSTM) en utilisant trois ensembles de donnÃ©es publics (Oxford, NASA et CALCE). La performance a Ã©tÃ© Ã©valuÃ©e Ã  l'aide de cinq mÃ©triques : l'erreur absolue moyenne (MAE), l'erreur absolue moyenne en pourcentage (MAPE), l'erreur quadratique moyenne (RMSE), le coefficient de dÃ©termination (R2) et l'erreur quadratique moyenne racine moyenne (ARMSE). L'Ã©tude a couvert divers matÃ©riaux de batterie (LCO, NCA, NCO) et formats (poche, cylindrique, prismatique).",
            "sec3-1-title": "1. PrÃ©cision et capacitÃ© de gÃ©nÃ©ralisation",
            "sec3-1-p1": "Sur l'ensemble de donnÃ©es Oxford, le RMSE moyen du BMSFormer n'Ã©tait que de <strong>0,0031</strong>. Par rapport aux quatre autres modÃ¨les, la rÃ©duction moyenne du MAE variait de 14,81 % Ã  73,56 %, et la rÃ©duction moyenne du MAPE variait de 20,00 % Ã  76,32 %.Sur les ensembles de donnÃ©es NASA et CALCE, face au phÃ©nomÃ¨ne de rÃ©gÃ©nÃ©ration de capacitÃ©, le BMSFormer a dÃ©montrÃ© une capacitÃ© de suivi supÃ©rieure avec des fluctuations d'erreur plus faibles, produisant des courbes de prÃ©diction qui correspondaient le plus Ã©troitement aux valeurs rÃ©elles. Sa rÃ©duction moyenne du MAE variait de 23,67 % Ã  47,90 %, et la rÃ©duction moyenne du MAPE variait de 20,42 % Ã  53,71 %.",
            "sec3-2-title": "2. EfficacitÃ© de calcul et consommation de ressources",
            "sec3-2-p1": "Dans des conditions d'entraÃ®nement identiques, la taille du modÃ¨le BMSFormer n'est que de<strong> 36,37 Ko</strong>. ComparÃ© au CNN-Transformer (47,10 Ko) et au Transformer (39,48 Ko), qui ont obtenu des performances de prÃ©cision relativement bonnes, le BMSFormer est plus adaptÃ© Ã  l'espace de stockage limitÃ© des puces embarquÃ©es. De plus, le BMSFormer a atteint le temps d'entraÃ®nement le plus court de 19,83 secondes.",
            "tab-1": "Tableau 1 Performance globale des modÃ¨les sous des configurations identiques et optimales.",
            "sec3-3-title": "3. Robustesse",
            "sec3-3-p1": "Les auteurs ont entraÃ®nÃ© et validÃ© les cinq modÃ¨les sur l'ensemble d'entraÃ®nement en utilisant 384 combinaisons d'hyperparameters diffÃ©rentes. Ces hyperparameters comprenaient le nombre d'Ã©poques, le taux d'apprentissage (learning rate), le nombre de blocs, le nombre de couches, la dimension dense et la dimension d'embedding.",
            "tab-2": "Tableau 2 Combinaisons d'hyperparamÃ¨tres.",
            "sec3-3-p2": "Le BMSFormer a fait preuve de performances et d'une prÃ©cision robustes Ã  travers diffÃ©rentes combinaisons d'hyperparameters. Plus prÃ©cisÃ©ment, 41 combinaisons ont produit des modÃ¨les de prÃ©diction avec une valeur R2 supÃ©rieure Ã  0,98, et 43,23 % des combinaisons avaient une valeur R2 supÃ©rieure Ã  0,9. Il a Ã©galement atteint la valeur R2 la plus Ã©levÃ©e de 0,9892. Ces rÃ©sultats indiquent que le modÃ¨le est peu sensible aux hyperparameters, ce qui facilite son rÃ©glage dans les applications d'ingÃ©nierie rÃ©elles.",
            "fig-5": "Fig. 5 RÃ©sultats globaux de validation selon diffÃ©rents modÃ¨les et combinaisons d'hyperparamÃ¨tres.",
            "sec4-title": "IV. Conclusion",
            "sec4-p1": "En introduisant le mÃ©canisme d'Attention de Fusion Locale-Globale (LGFA) et la Convolution SÃ©parable en Profondeur (DSConv) multi-Ã©chelle, le modÃ¨le BMSFormer s'efforce de condenser les puissantes capacitÃ©s du Transformer dans un modÃ¨le compact. Cela offre une voie alternative pour rÃ©soudre le problÃ¨me de la rÃ©alisation d'une estimation du SOH de haute prÃ©cision et Ã  faible latence sur des plateformes Ã  faible puissance de calcul.",
            "ref-title": "RÃ©fÃ©rence originale",
            "footer-slogan": "ModÃ¨le efficace pour BMS Ã  ressources limitÃ©es",
            "footer-tech": "Attention fusionnÃ©e &bull; Fusion de caractÃ©ristiques profondes"
        },
        // ================== å¾·è¯­ Deutsch ==================
        "de": {
            "nav-title": "Navigation",
            "nav-1": "I. Herausforderungen im BMS",
            "nav-2": "II. Innovationen des BMSFormer",
            "nav-2-1": "1. Beschneidung redundanter Daten",
            "nav-2-2": "2. Local-Global Fusion Attention (LGFA)-Mechanismus",
            "nav-2-3": "3. Mehrskalige Depthwise Separable Convolution (DSConv)",
            "nav-3": "III. Empirische Bewertung auf DatensÃ¤tzen",
            "nav-3-1": "1. Genauigkeit und GeneralisierungsfÃ¤higkeit",
            "nav-3-2": "2. Recheneffizienz und Ressourcenverbrauch",
            "nav-3-3": "3. Robustheit",
            "nav-4": "IV. Zusammenfassung",
            "nav-ref": "Originalreferenz",
            "tag-note": "[Studiennotiz]",
            "main-title": "BMSFormer: Ein effizientes Online-SOH-SchÃ¤tzmodell fÃ¼r ressourcenbeschrÃ¤nkte BMS",
            "btn-link": "Originallink (ScienceDirect)",
            "info-title-label": "Titel der Arbeit:",
            "info-title-val": "BMSFormer: An efficient deep learning model for online state-of-health estimation of lithium-ion batteries under high-frequency early SOC data with strong correlated single health indicator",
            "info-journal-label": "Journal:",
            "info-journal-val": "Energy, 2024",
            "info-keywords-label": "SchlÃ¼sselwÃ¶rter: ",
            "info-keywords-val": "Gesundheitszustand (SOH); Lithium-Ionen-Batterie; EffizienzschÃ¤tzung; Lokal-Globale Fusionsaufmerksamkeit; Tiefe Merkmalsfusion",
            "sec1-title": "I. Herausforderungen im BMS",
            "sec1-p1": "Sicherheit und Lebensdauermanagement von Lithium-Ionen-Batterien sind in der heutigen Zeit zentrale Themen, wobei die SchÃ¤tzung des Gesundheitszustands (State of Health, SOH) eine Kernfunktion des Batteriemanagementsystems (BMS) darstellt. In der praktischen BMS-Entwicklung stehen Ingenieure vor drei Hauptproblemen:<br><strong>(1) Begrenzungen bei Rechenleistung und Speicherplatz</strong><br>Eingebettete BMS-Chips verfÃ¼gen Ã¼ber begrenzten Speicherplatz und Rechenleistung. Im Gegensatz dazu weisen Modelle wie der Transformer eine enorme Anzahl an Parametern auf, was sie fÃ¼r solche Chips zu schwergewichtig macht.<br><strong>(2) Unzureichende EchtzeitfÃ¤higkeit und StabilitÃ¤t</strong><br>Viele Modelle besitzen komplexe Strukturen und lange Inferenzzeiten. Zudem sind sie oft empfindlich gegenÃ¼ber Hyperparameter-Einstellungen, was es schwierig macht, die Anforderungen an EchtzeitschÃ¤tzung und BetriebsstabilitÃ¤t zu erfÃ¼llen.<br><strong>(3) Unzureichende Genauigkeit</strong><br>Einige Modelle stÃ¼tzen sich auf Gesundheitsindikatoren (HIs) mit unzureichender ReprÃ¤sentationsfÃ¤higkeit oder extrahieren schwach korrelierte Indikatoren, was zu einer beeintrÃ¤chtigten SchÃ¤tzgenauigkeit fÃ¼hrt.",
            "sec1-p2": "Um diese Probleme anzugehen, schlÃ¤gt diese Arbeit das leichtgewichtige Modell <strong>BMSFormer (Battery Management System Transformer)</strong> vor. BMSFormer behÃ¤lt die FÃ¤higkeiten zur Merkmalsextraktion des Transformer-Modells bei, reduziert jedoch effektiv die RechenkomplexitÃ¤t und den Speicherbedarf ohne EinbuÃŸen bei der Genauigkeit, wodurch es sich fÃ¼r ressourcenbeschrÃ¤nkte BMS-Umgebungen eignet.",
            "sec2-title": "II. Innovationen des BMSFormer",
            "sec2-intro": "BMSFormer ist nicht bloÃŸ eine einfache Anwendung des Transformer; vielmehr handelt es sich um ein leichtgewichtiges, hocheffizientes Modell, das tiefgreifend rekonstruiert wurde, um den Eigenschaften von Batterie-Zeitreihendaten gerecht zu werden.",
            "fig-1": "Abb.1 Rahmenwerk des BMSFormer-Modells: (a) Local-Global Fusion Attention (LGFA)-Modul; (b) BMSFormer-Block; (c) DSConv-L-Modul; (d) Kernstruktur des BMSFormer.",
            "sec2-1-title": "1. Beschneidung redundanter Daten",
            "sec2-1-p1": "Traditionelle SOH-SchÃ¤tzungen erfordern vollstÃ¤ndige Lade-Entlade-Zyklusdaten, was in realen Anwendungen oft schwer umzusetzen ist. BMSFormer schlÃ¤gt eine optimierte Strategie zur Merkmalsextraktion vor:<br><strong>(1) Fokussierung auf Hochfrequenz-Intervalle</strong><br>Das Modell wÃ¤hlt Spannungsintervalle aus, die im tÃ¤glichen Batteriebetrieb am hÃ¤ufigsten auftreten, konkret das Ladeintervall von 3,8 V bis 4,2 V und das Entladeintervall von 3,8 V bis 3,4 V.<br><strong>(2) Einzelner Gesundheitsindikator</strong><br>Unter Verwendung einer Sliding-Window-Technik (Schiebefenster) mit progressiv abnehmender FenstergrÃ¶ÃŸe und Schrittweite filtert das Modell den einzelnen Gesundheitsindikator (HIs) heraus, der am stÃ¤rksten mit dem SOH korreliert, wobei ein Korrelationskoeffizient nach Pearson (PCC) von mehr als 0,99 erreicht wird.<br>Unter dieser Strategie muss BMSFormer nur diese kurzen Datenfragmente von wenigen Minuten erfassen, um den Batteriezustand Ã¼ber den stark korrelierten einzelnen HI schnell zu beurteilen.",
            "fig-2": "Abb.2 Extraktionsprozess des ausgewÃ¤hlten Gesundheitsindikators (HI) innerhalb des gewÃ¤hlten Ladeintervalls.",
            "sec2-2-title": "2. Local-Global Fusion Attention (LGFA)-Mechanismus",
            "sec2-2-p1": "Traditionelle Transformer-Modelle verwenden den Softmax-Attention-Mechanismus, dessen RechenkomplexitÃ¤t quadratisch mit der SequenzlÃ¤nge wÃ¤chst, was zu prohibitiven Rechenkosten bei groÃŸen Sequenzen fÃ¼hrt. BMSFormer fÃ¼hrt das <strong>LGFA-Modul (Local-Global Fusion Attention)</strong> ein, um dieses Problem zu lÃ¶sen.<br><strong>(1) Von exponentiell zu linear</strong><br>Durch den Ersatz des traditionellen Softmax durch einen linearen ReLU-Attention-Mechanismus wird die RechenkomplexitÃ¤t auf eine lineare Skala reduziert.<br><strong>(2) Verbesserung lokaler Merkmale</strong><br>Lineare Attention-Mechanismen neigen dazu, Details zu verlieren. Das LGFA-Modul integriert Depthwise Separable Convolution (DSConv), wodurch das Modell in der Lage ist, globale Entwicklungstrends zu erfassen und gleichzeitig die SensitivitÃ¤t fÃ¼r lokale Merkmale der Spannungsschwankungen beizubehalten.",
            "fig-3": "Abb.3 Vergleich verschiedener Attention-Mechanismen: (a) Traditioneller Softmax-Attention-Mechanismus; (b) Traditioneller linearer Attention-Mechanismus; (c) Local-Global Fusion Attention (LGFA)-Modul.",
            "sec2-3-title": "3. Mehrskalige Depthwise Separable Convolution (DSConv)",
            "sec2-3-p1": "BMSFormer verwendet <strong>Depthwise Separable Convolution (DSConv)</strong> anstelle von Standard-Faltung, um das Modell leichtgewichtiger zu machen.<br><strong>(1) DSConv-S</strong><br>Nutzt einen 2-fachen Erweiterungsfaktor fÃ¼r EingangskanÃ¤le und eine KernelgrÃ¶ÃŸe der Tiefenfaltung von 1Ã—3, zustÃ¤ndig fÃ¼r die Extraktion kurzfristiger, subtiler MerkmalsÃ¤nderungen.<br><strong>(2) DSConv-L</strong><br>Nutzt einen 3-fachen Erweiterungsfaktor fÃ¼r EingangskanÃ¤le und eine KernelgrÃ¶ÃŸe der Tiefenfaltung von 1Ã—31, zustÃ¤ndig fÃ¼r die Extraktion langfristiger, globaler Degradationstrends.",
            "fig-4": "Abb.4 Schema der Grundstrukturen: (a) Standard-Faltung; (b) Standard Depthwise Separable Convolution; (c) DSConv-S-Modul; (d) DSConv-L-Modul.",
            "sec3-title": "III. Empirische Bewertung auf DatensÃ¤tzen",
            "sec3-intro": "Die Autoren fÃ¼hrten eine umfassende Bewertung von fÃ¼nf Modellen (BMSFormer, CNN-Transformer, CNN-LSTM, Transformer und LSTM) unter Verwendung von drei Ã¶ffentlichen DatensÃ¤tzen (Oxford, NASA und CALCE). Die Leistung wurde anhand von fÃ¼nf Metriken bewertet: Mittlerer absoluter Fehler (MAE), Mittlerer absoluter prozentualer Fehler (MAPE), Wurzel des mittleren quadratischen Fehlers (RMSE), BestimmtheitsmaÃŸ (R2) und durchschnittlicher RMSE (ARMSE). Die Studie deckte verschiedene Batteriematerialien (LCO, NCA, NCO) und Bauformen (Pouch, Zylindrisch, Prismatisch) ab.",
            "sec3-1-title": "1. Genauigkeit und GeneralisierungsfÃ¤higkeit",
            "sec3-1-p1": "Auf dem Oxford-Datensatz betrug der durchschnittliche RMSE von BMSFormer nur <strong>0,0031</strong>. Im Vergleich zu den anderen vier Modellen lag die Reduktion des durchschnittlichen MAE zwischen 14,81 % und 73,56 %, und die Reduktion des durchschnittlichen MAPE lag zwischen 20,00 % und 76,32 %.Auf den NASA- und CALCE-DatensÃ¤tzen zeigte BMSFormer beim Auftreten des PhÃ¤nomens der KapazitÃ¤tsregeneration eine Ã¼berlegene Tracking-FÃ¤higkeit mit geringeren Fehlerschwankungen, wobei die Vorhersagekurven den tatsÃ¤chlichen Werten am nÃ¤chsten kamen. Die Reduktion des durchschnittlichen MAE lag zwischen 23,67 % und 47,90 %, und die Reduktion des durchschnittlichen MAPE lag zwischen 20,42 % und 53,71 %.",
            "sec3-2-title": "2. Recheneffizienz und Ressourcenverbrauch",
            "sec3-2-p1": "Unter identischen Trainingsbedingungen betrÃ¤gt die GrÃ¶ÃŸe des BMSFormer-Modells nur<strong> 36,37 KB</strong>. Im Vergleich zu CNN-Transformer (47,10 KB) und Transformer (39,48 KB), die relativ gute Genauigkeitswerte erzielten, eignet sich BMSFormer besser fÃ¼r den begrenzten Speicherplatz eingebetteter Chips. Zudem erreichte BMSFormer die kÃ¼rzeste Trainingszeit von 19,83 Sekunden.",
            "tab-1": "Tabelle 1 Gesamtleistung der Modelle unter identischen und optimalen Konfigurationen.",
            "sec3-3-title": "3. Robustheit",
            "sec3-3-p1": "Die Autoren trainierten und validierten die fÃ¼nf Modelle auf dem Trainingsdatensatz unter Verwendung von 384 verschiedenen Hyperparameter-Kombinationen. Diese Hyperparameter umfassten die Anzahl der Epochen, Lernrate (learning rate), Anzahl der BlÃ¶cke, Anzahl der Schichten, Dense-Dimension und Embedding-Dimension.",
            "tab-2": "Tabelle 2 Hyperparameter-Kombinationen.",
            "sec3-3-p2": "BMSFormer zeigte robuste Leistung und Genauigkeit Ã¼ber verschiedene Hyperparameter-Kombinationen hinweg. Konkret lieferten 41 Kombinationen Vorhersagemodelle mit einem R2-Wert von Ã¼ber 0,98, und 43,23 % der Kombinationen hatten einen R2-Wert von mehr als 0,9. Es wurde zudem der hÃ¶chste R2-Wert von 0,9892 erreicht. Diese Ergebnisse deuten darauf hin, dass das Modell unempfindlich gegenÃ¼ber Hyperparametern ist, was die Abstimmung in praktischen technischen Anwendungen erleichtert.",
            "fig-5": "Abb.5 Gesamtvalidierungsergebnisse unter verschiedenen Modellen und Hyperparameter-Kombinationen.",
            "sec4-title": "IV. Zusammenfassung",
            "sec4-p1": "Durch die EinfÃ¼hrung des Local-Global Fusion Attention (LGFA)-Mechanismus und der mehrskaligen Depthwise Separable Convolution (DSConv) zielt das BMSFormer-Modell darauf ab, die leistungsfÃ¤higen FÃ¤higkeiten des Transformer in einem kompakten Modell zu kondensieren. Dies bietet einen alternativen LÃ¶sungsansatz fÃ¼r das Problem, eine hochprÃ¤zise SOH-SchÃ¤tzung mit geringer Latenz auf Plattformen mit geringer Rechenleistung zu realisieren.",
            "ref-title": "Originalreferenz",
            "footer-slogan": "Effizientes Modell fÃ¼r ressourcenbeschrÃ¤nkte BMS",
            "footer-tech": "Lokal-Globale Fusionsaufmerksamkeit &bull; Tiefe Merkmalsfusion"
        }
    };

    const defaultContent = {};

    // 4. åˆå§‹åŒ–ä¸è·¯ç”±é€»è¾‘ (æ–°å¢)
    document.addEventListener("DOMContentLoaded", function() {
        // ä¿å­˜é»˜è®¤ä¸­æ–‡å†…å®¹
        const elements = document.querySelectorAll("[data-i18n]");
        elements.forEach(el => {
            const key = el.getAttribute("data-i18n");
            defaultContent[key] = el.innerHTML;
        });

        // æ£€æŸ¥ URL hash å¹¶è®¾ç½®åˆå§‹è¯­è¨€
        checkHashAndSetLanguage();
    });

    // ç›‘å¬ Hash å˜åŒ– (æ”¯æŒæµè§ˆå™¨åé€€/å‰è¿›æŒ‰é’®)
    window.addEventListener('hashchange', checkHashAndSetLanguage);

    function checkHashAndSetLanguage() {
        // è·å– URL hashï¼Œä¾‹å¦‚ "#us" -> "us"
        let hash = window.location.hash.slice(1);

        // æ˜ å°„è§„åˆ™ï¼šå¦‚æœç”¨æˆ·è¾“å…¥ #usï¼Œæˆ‘ä»¬å°†å…¶è§†ä¸º 'en' (è‹±è¯­)ï¼Œä»¥ä¾¿åŒ¹é…æ‚¨çš„ translations å¯¹è±¡
        if (hash === 'us') hash = 'en';

        // éªŒè¯è¯­è¨€æ˜¯å¦æœ‰æ•ˆï¼Œå¦‚æœæ— æ•ˆåˆ™é»˜è®¤ä¸º 'zh'
        const validLangs = ['zh', 'en', 'fr', 'de'];
        const lang = validLangs.includes(hash) ? hash : 'zh';

        // åŒæ­¥ä¸‹æ‹‰èœå•çš„å€¼
        const selector = document.getElementById('language-selector');
        if (selector) {
            selector.value = lang;
        }

        // æ‰§è¡Œç¿»è¯‘æ›¿æ¢ (ä¼ å…¥ false é˜²æ­¢æ— é™å¾ªç¯æ›´æ–° URL)
        changeLanguage(lang, false);
    }

    // åˆ‡æ¢è¯­è¨€å‡½æ•°
    function changeLanguage(lang, updateUrl = true) {
        const elements = document.querySelectorAll("[data-i18n]");

        elements.forEach(el => {
            const key = el.getAttribute("data-i18n");

            if (lang === "zh") {
                if (defaultContent[key]) {
                    el.innerHTML = defaultContent[key];
                }
            } else {
                // å¦‚æœæ˜¯ 'us'ï¼Œåœ¨ translations é‡Œæ‰¾ 'en'
                const jsonKey = (lang === 'us') ? 'en' : lang;

                if (translations[jsonKey] && translations[jsonKey][key]) {
                    el.innerHTML = translations[jsonKey][key];
                }
            }
        });

        // æ›´æ–° URL Hash
        if (updateUrl) {
            if (lang === "zh") {
                // ä¸­æ–‡æ—¶ç§»é™¤ hashï¼Œä¿æŒ URL å¹²å‡€
                history.pushState("", document.title, window.location.pathname + window.location.search);
            } else {
                // å¦‚æœé€‰çš„æ˜¯ enï¼ŒURL æ˜¾ç¤º #us (æ ¹æ®æ‚¨çš„éœ€æ±‚)
                const urlHash = (lang === 'en') ? 'us' : lang;
                window.location.hash = urlHash;
            }
        }
    }
</script>
</body>
</html>
